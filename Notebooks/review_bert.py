{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7685145,"sourceType":"datasetVersion","datasetId":4484328}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\nfrom transformers import TrainingArguments, Trainer\nfrom transformers import DataCollatorWithPadding\nfrom datasets import Dataset\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score, accuracy_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-24T19:55:14.047724Z","iopub.execute_input":"2024-08-24T19:55:14.048503Z","iopub.status.idle":"2024-08-24T19:55:32.512361Z","shell.execute_reply.started":"2024-08-24T19:55:14.048461Z","shell.execute_reply":"2024-08-24T19:55:32.511575Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    n_splits = 1\n    seed = 42\n    max_length = 512\n    lr = 1e-5\n    train_batch_size = 4\n    eval_batch_size = 8\n    train_epochs = 2\n    weight_decay = 0.01\n    warmup_ratio = 0.1\n    num_labels = 10","metadata":{"execution":{"iopub.status.busy":"2024-08-24T19:55:37.157284Z","iopub.execute_input":"2024-08-24T19:55:37.158094Z","iopub.status.idle":"2024-08-24T19:55:37.163607Z","shell.execute_reply.started":"2024-08-24T19:55:37.158054Z","shell.execute_reply":"2024-08-24T19:55:37.162512Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/drug-review-prediction-sentiment-analysis/textsentiment.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-24T19:55:38.554911Z","iopub.execute_input":"2024-08-24T19:55:38.555292Z","iopub.status.idle":"2024-08-24T19:55:40.599413Z","shell.execute_reply.started":"2024-08-24T19:55:38.555255Z","shell.execute_reply":"2024-08-24T19:55:40.598396Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                   drugName                     condition  \\\n0                 Valsartan  Left Ventricular Dysfunction   \n1                Guanfacine                          ADHD   \n2                    Lybrel                 Birth Control   \n3                Ortho Evra                 Birth Control   \n4  Buprenorphine / naloxone             Opiate Dependence   \n\n                                              review  rating  \n0  It has no side effect, I take it in combinatio...       9  \n1  My son is halfway through his fourth week of I...       8  \n2  I used to take another oral contraceptive, whi...       5  \n3  This is my first time using any form of birth ...       8  \n4  Suboxone has completely turned my life around....       9  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>drugName</th>\n      <th>condition</th>\n      <th>review</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Valsartan</td>\n      <td>Left Ventricular Dysfunction</td>\n      <td>It has no side effect, I take it in combinatio...</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Guanfacine</td>\n      <td>ADHD</td>\n      <td>My son is halfway through his fourth week of I...</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Lybrel</td>\n      <td>Birth Control</td>\n      <td>I used to take another oral contraceptive, whi...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Ortho Evra</td>\n      <td>Birth Control</td>\n      <td>This is my first time using any form of birth ...</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Buprenorphine / naloxone</td>\n      <td>Opiate Dependence</td>\n      <td>Suboxone has completely turned my life around....</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df['review']= \"The name of the drug I used is \"+df['drugName']+\". I was prescribed the same for \"+df['condition']+\". \"+df['review']\ndf=df.drop(['drugName', 'condition'], axis=1)\ndf = df.rename(columns={'review': 'text', 'rating': 'label'})\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-24T19:55:54.702339Z","iopub.execute_input":"2024-08-24T19:55:54.703273Z","iopub.status.idle":"2024-08-24T19:55:54.996276Z","shell.execute_reply.started":"2024-08-24T19:55:54.703231Z","shell.execute_reply":"2024-08-24T19:55:54.995262Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                text  label\n0  The name of the drug I used is Valsartan. I wa...      9\n1  The name of the drug I used is Guanfacine. I w...      8\n2  The name of the drug I used is Lybrel. I was p...      5\n3  The name of the drug I used is Ortho Evra. I w...      8\n4  The name of the drug I used is Buprenorphine /...      9","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The name of the drug I used is Valsartan. I wa...</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The name of the drug I used is Guanfacine. I w...</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The name of the drug I used is Lybrel. I was p...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The name of the drug I used is Ortho Evra. I w...</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The name of the drug I used is Buprenorphine /...</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"class Tokenize(object):\n    def __init__(self, train, valid, tokenizer):\n        self.tokenizer = tokenizer\n        self.train = train\n        self.valid = valid\n        \n    def get_dataset(self, df):\n        ds = Dataset.from_dict({\n                'text': [ft for ft in df['text']],\n                'label': [s for s in df['label']],\n            })\n        return ds\n        \n    def tokenize_function(self, example):\n        tokenized_inputs = self.tokenizer(\n            example['text'], truncation=True, max_length=CFG.max_length\n        )\n        return tokenized_inputs\n    \n    def __call__(self):\n        train_ds = self.get_dataset(self.train)\n        valid_ds = self.get_dataset(self.valid)\n        \n        tokenized_train = train_ds.map(\n            self.tokenize_function, batched=True\n        )\n        tokenized_valid = valid_ds.map(\n            self.tokenize_function, batched=True\n        )\n        \n        return tokenized_train, tokenized_valid, self.tokenizer","metadata":{"execution":{"iopub.status.busy":"2024-08-24T19:55:56.268434Z","iopub.execute_input":"2024-08-24T19:55:56.269138Z","iopub.status.idle":"2024-08-24T19:55:56.276960Z","shell.execute_reply.started":"2024-08-24T19:55:56.269098Z","shell.execute_reply":"2024-08-24T19:55:56.275930Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    \n    predictions, labels = eval_pred\n    f1 = f1_score(labels, predictions.clip(0,9).round(0), average='macro')\n    acc = accuracy_score(labels, predictions.clip(0,9).round(0))\n    results = {\n        'f1': f1,\n        'acc':acc\n    }\n    return results","metadata":{"execution":{"iopub.status.busy":"2024-08-24T19:55:58.650065Z","iopub.execute_input":"2024-08-24T19:55:58.650731Z","iopub.status.idle":"2024-08-24T19:55:58.656060Z","shell.execute_reply.started":"2024-08-24T19:55:58.650692Z","shell.execute_reply":"2024-08-24T19:55:58.655117Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"\ndf['label'] = df['label'].apply(lambda x: x-1).astype('float32')\n\n\n# skf = StratifiedKFold(n_splits=CFG.n_splits, shuffle=True, random_state=CFG.seed)\n# for i, (_, val_index) in enumerate(skf.split(df, df[\"label\"])):\n#     df.loc[val_index, \"fold\"] = i\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-24T19:55:59.894926Z","iopub.execute_input":"2024-08-24T19:55:59.895748Z","iopub.status.idle":"2024-08-24T19:56:00.044164Z","shell.execute_reply.started":"2024-08-24T19:55:59.895707Z","shell.execute_reply":"2024-08-24T19:56:00.043103Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                text  label\n0  The name of the drug I used is Valsartan. I wa...    8.0\n1  The name of the drug I used is Guanfacine. I w...    7.0\n2  The name of the drug I used is Lybrel. I was p...    4.0\n3  The name of the drug I used is Ortho Evra. I w...    7.0\n4  The name of the drug I used is Buprenorphine /...    8.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The name of the drug I used is Valsartan. I wa...</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The name of the drug I used is Guanfacine. I w...</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The name of the drug I used is Lybrel. I was p...</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The name of the drug I used is Ortho Evra. I w...</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The name of the drug I used is Buprenorphine /...</td>\n      <td>8.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=f'output_v1',\n    fp16=True,\n    learning_rate=CFG.lr,\n    per_device_train_batch_size=CFG.train_batch_size,\n    per_device_eval_batch_size=CFG.eval_batch_size,\n    num_train_epochs=CFG.train_epochs,\n    weight_decay=CFG.weight_decay,\n    eval_strategy='epoch',\n    metric_for_best_model='f1',\n    save_strategy='epoch',\n    save_total_limit=1,\n    load_best_model_at_end=True,\n    report_to='none',\n    warmup_ratio=CFG.warmup_ratio,\n    lr_scheduler_type='cosine',\n    optim='adamw_torch',\n    logging_first_step=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T19:56:01.476630Z","iopub.execute_input":"2024-08-24T19:56:01.477303Z","iopub.status.idle":"2024-08-24T19:56:01.563349Z","shell.execute_reply.started":"2024-08-24T19:56:01.477264Z","shell.execute_reply":"2024-08-24T19:56:01.562477Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"\n    \n# GET TRAIN AND VALID DATA\n# train = df[df['fold'] != fold]\n# valid = df[df['fold'] == fold].copy()\ntrain=df.iloc[:150000,:]\nvalid=df.iloc[150000:, :]\n\n# ADD NEW TOKENS for (\"\\n\") new paragraph and (\" \"*2) double space \ntokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-v3-small')\n\ntokenize = Tokenize(train, valid, tokenizer)\ntokenized_train, tokenized_valid, _ = tokenize()\n\n# REMOVE DROPOUT FROM REGRESSION\nconfig = AutoConfig.from_pretrained('microsoft/deberta-v3-small')\n\nconfig.attention_probs_dropout_prob = 0.0 \nconfig.hidden_dropout_prob = 0.0 \nconfig.num_labels = 1 \n\nmodel = AutoModelForSequenceClassification.from_pretrained('microsoft/deberta-v3-small', config=config)\nmodel.resize_token_embeddings(len(tokenizer))\n\n# TRAIN WITH TRAINER\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\ntrainer = Trainer( \n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_valid,\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n)\ntrainer.train()\n\n# PLOT CONFUSION MATRIX\ny_true = valid['score'].values\npredictions0 = trainer.predict(tokenized_valid).predictions\npredictions = predictions0.round(0) + 1\ncm = confusion_matrix(y_true, predictions, labels=[x for x in range(1,11)])\ndraw_cm = ConfusionMatrixDisplay(confusion_matrix=cm,\n                              display_labels=[x for x in range(1,11)])\ndraw_cm.plot()\nplt.show()\n\n# SAVE FOLD MODEL AND TOKENIZER\ntrainer.save_model(f'bkl_mkc')\ntokenizer.save_pretrained(f'bkl_mkc')","metadata":{"execution":{"iopub.status.busy":"2024-08-24T19:56:03.683496Z","iopub.execute_input":"2024-08-24T19:56:03.683935Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4823b77ee65f4ee6b19cbb7135d496ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/578 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2162f979fca848e28c5cdc60725992b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c8d2c9abb3e402288dde35606c5d6d7"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:551: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/150000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f56b814213b44d199c5710c2e022ff4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/63869 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc96cf4ab8ed482883d894596ec2bc0d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/286M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c7d2fcfe2ee45c982a3c15c6b431216"}},"metadata":{}},{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='67774' max='75000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [67774/75000 1:42:33 < 10:56, 11.01 it/s, Epoch 1.81/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n      <th>Acc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>2.252600</td>\n      <td>2.129433</td>\n      <td>0.321949</td>\n      <td>0.425653</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}